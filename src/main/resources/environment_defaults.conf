env.name=ide
cluster.name=${component.name}"-"${env.name}
instance.name=node-0
instance.fqn=${cluster.name}"-"${instance.name}
log.path.current=/tmp/logs/${instance.fqn}
log.path.archive=/tmp/logs/${instance.fqn}/archive
log.level=INFO
sysout.detach=false
syserr.detach=false
daemon.pidfile=${log.path.current}/${instance.fqn}.pid
server.root =
{
  type=com.askme.mandelbrot.server.RootServer
  port=9999
  host="127.0.0.1"
  timeout=5
  actorSystem {
    name=${cluster.name}"-akka"
    akka {
      loggers = ["akka.event.slf4j.Slf4jLogger"]
      loglevel = INFO
    }
    spray {
      can.server {
        server-header = ${component.name}
        remote-address-header=on
        request-timeout=8 s
        idle-timeout=12 s
      }
      routing {
        relaxed-header-parsing = on
      }
    }
  }

  kafka {
    producer {
      client.id = mandelbrot-producer
      bootstrap.servers = "localhost:9092"
      key.serializer = org.apache.kafka.common.serialization.StringSerializer
      value.serializer = org.apache.kafka.common.serialization.StringSerializer
    }
  }

  es {
    cluster.name=${cluster.name}
    node {
      name = ${instance.name}
      data = true
      master = true
    }
    discovery.zen {
      ping.multicast.enabled = false
      ping.unicast.hosts = ${server.root.host}
      minimum_master_nodes = 1
    }
    network.host="127.0.0.1"
    path {
      data = "/tmp/data/es"
      logs = ${log.path.current}
      conf = "/tmp/esconfig"
    }
    indices {
      cache.query.size: "20%"
      cache.filter.size: "40%"
      fielddata.cache.size: "2%"
      memory.index_buffer_size: "2048mb"
      memory.max_index_buffer_size: "2048mb"
      memory.min_index_buffer_size: "2048mb"
      store.throttle.max_bytes_per_sec: "20mb"
      store.throttle.type: "merge"
    }
    logger.index.search.slowlog.threshold.query.warn: 1s
    gateway {
      recover_after_nodes: 1
      expected_nodes: 1
      recover_after_time: 2m
    }
    script.native {
      geobucket.type = com.askme.mandelbrot.scripts.GeoBucket
      docscore.type = com.askme.mandelbrot.scripts.DocScore
    }

  }

  hazel {
    logging.type=slf4j
    multicast.enabled=false
    tcpip.enabled=true
    tcpip.members=[${server.root.host}]
    tcpip.required.member=${server.root.host}
    port.number=5701
    port.autoincrement=false
    interfaces=["192.168.*.*"]
    interface.enabled=true
  }

  spark {
    master="local[4]"
    app.name=${instance.fqn}
    executor.memory="1g"
    shuffle.spill="true"
    logConf="true"
    local.dir="/tmp"
    streaming.batch.duration=2
  }

  handler {
    name=${instance.fqn}"-http"
    timeoutms=5000
    max-docs-per-shard=500000
    http.indexing.enabled = false
    http.aggregate.enabled = false
  }

  threads {
    batch=2
    user=8
  }
}
